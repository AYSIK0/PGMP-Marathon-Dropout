{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Data cleaning and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from utils.data_processing_utils import london_cleaner, hamburg_cleaner, stockholm_cleaner, boston_cleaner, \\\n",
    "                                        chicago_cleaner, houston_cleaner, save_df, valid_df, get_indices_of_rows_missing_data, preprocess_impute_fill, valid_splits_time\n",
    "# from utils.data_processing_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"Marathons_Data/Raw\"\n",
    "CLN_DATA_PATH = \"Marathons_Data/Clean\"\n",
    "IMP_DATA_PATH = \"Marathons_Data/Impute\"\n",
    "# London\n",
    "LDN: str = \"London\"\n",
    "LDN_RAW_PATH: str = f\"{RAW_DATA_PATH}/{LDN}\"\n",
    "LDN_CLN_PATH: str = f\"{CLN_DATA_PATH}/{LDN}\"\n",
    "LDN_IMP_PATH: str = f\"{IMP_DATA_PATH}/{LDN}\"\n",
    "# Hamburg\n",
    "HAM: str = \"Hamburg\"\n",
    "HAM_RAW_PATH: str = f\"{RAW_DATA_PATH}/{HAM}\"\n",
    "HAM_CLN_PATH: str = f\"{CLN_DATA_PATH}/{HAM}\"\n",
    "HAM_IMP_PATH: str = f\"{IMP_DATA_PATH}/{HAM}\"\n",
    "# Houston\n",
    "HOU: str = \"Houston\"\n",
    "HOU_RAW_PATH: str = f\"{RAW_DATA_PATH}/{HOU}\"\n",
    "HOU_CLN_PATH: str = f\"{CLN_DATA_PATH}/{HOU}\"\n",
    "HOU_IMP_PATH: str = f\"{IMP_DATA_PATH}/{HOU}\"\n",
    "# Stockholm\n",
    "STO: str = \"Stockholm\"\n",
    "STO_RAW_PATH: str = f\"{RAW_DATA_PATH}/{STO}\"\n",
    "STO_CLN_PATH: str = f\"{CLN_DATA_PATH}/{STO}\"\n",
    "STO_IMP_PATH: str = f\"{IMP_DATA_PATH}/{STO}\"\n",
    "# Boston\n",
    "BOS: str = \"Boston\"\n",
    "BOS_RAW_PATH: str = f\"{RAW_DATA_PATH}/{BOS}\"\n",
    "BOS_CLN_PATH: str = f\"{CLN_DATA_PATH}/{BOS}\"\n",
    "BOS_IMP_PATH: str = f\"{IMP_DATA_PATH}/{BOS}\"\n",
    "# Chicago\n",
    "CHI: str = \"Chicago\"\n",
    "CHI_RAW_PATH: str = f\"{RAW_DATA_PATH}/{CHI}\"\n",
    "CHI_CLN_PATH: str = f\"{CLN_DATA_PATH}/{CHI}\"\n",
    "CHI_IMP_PATH: str = f\"{IMP_DATA_PATH}/{CHI}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years & Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_13: str = \"2013\"\n",
    "YEAR_14: str = \"2014\"\n",
    "YEAR_15: str = \"2015\"\n",
    "YEAR_16: str = \"2016\"\n",
    "YEAR_17: str = \"2017\"\n",
    "YEAR_18: str = \"2018\"\n",
    "YEAR_19: str = \"2019\"\n",
    "YEAR_21: str = \"2021\"\n",
    "YEAR_22: str = \"2022\"\n",
    "YEAR_23: str = \"2023\"\n",
    "YEARS: list[str] = [YEAR_13, YEAR_14, YEAR_15, YEAR_16, YEAR_17, YEAR_18, YEAR_19, YEAR_21, YEAR_22, YEAR_23]\n",
    "SPLITS_KEYS: list[str] = [\"k_5\", \"k_10\", \"k_15\", \"k_20\", \"k_half\", \"k_25\", \"k_30\", \"k_35\", \"k_40\", \"k_finish\"]\n",
    "\n",
    "COLS_ORDER: list[str] = [\"age_cat\", \"gender\", \"race_state\", \"last_split\", \n",
    "                         'k_5_time', 'k_5_pace', 'k_5_speed', 'k_10_time', 'k_10_pace', 'k_10_speed',\n",
    "                         'k_15_time', 'k_15_pace', 'k_15_speed', 'k_20_time', 'k_20_pace', 'k_20_speed',\n",
    "                         'k_half_time', 'k_half_pace', 'k_half_speed', 'k_25_time', 'k_25_pace', 'k_25_speed', \n",
    "                         'k_30_time', 'k_30_pace', 'k_30_speed', 'k_35_time', 'k_35_pace', 'k_35_speed',\n",
    "                         'k_40_time', 'k_40_pace', 'k_40_speed', 'k_finish_time', 'k_finish_pace', 'k_finish_speed']\n",
    "\n",
    "SPLIT_NAME_DICT: dict = {'k_5_time': '5K', 'k_10_time': '10K', 'k_15_time': '15K', \n",
    "                         'k_20_time': '20K', 'k_25_time': '25K', 'k_half_time': 'HALF', \n",
    "                         'k_30_time': '30K', 'k_35_time': '35K', 'k_40_time': '40K', 'k_finish_time': 'Finish time'}\n",
    "\n",
    "DTYPE_DICT: defaultdict = defaultdict(np.float64, age_cat=\"category\", gender=\"category\", race_state=\"category\", last_split=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialise MinMaxScaler.\n",
    "mms = MinMaxScaler()\n",
    "# Intialise Imputers\n",
    "knn_imputer = KNNImputer()\n",
    "rfr = RandomForestRegressor(n_estimators=5, max_depth=10, bootstrap=True, max_samples=0.5, n_jobs=2, random_state=17)\n",
    "iter_imputer = IterativeImputer(estimator=rfr, max_iter=15, random_state=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDN_COLS_TO_DROP = [\"idp\", \"half\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw file path.\n",
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_14}/{LDN}{YEAR_14}_full.csv\"\n",
    "# Clean file path.\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_14}/{LDN}{YEAR_14}_clean.csv\"\n",
    "# Imputed files paths.\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_14}/{LDN}{YEAR_14}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_14}/{LDN}{YEAR_14}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 41677 || New rows count: 36289 || Dropped Rows: 5388\n",
      "** Dropping rows with splits that only contain time: Finished: 328 || Started: 27\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 35934 || New rows count: 35928 || Dropped rows based on   age_cat  : 6\n",
      "Original rows count: 35928 || New rows count: 35928 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2014/London2014_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_15}/{LDN}{YEAR_15}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_15}/{LDN}{YEAR_15}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_15}/{LDN}{YEAR_15}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_15}/{LDN}{YEAR_15}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 43741 || New rows count: 37879 || Dropped Rows: 5862\n",
      "** Dropping rows with splits that only contain time: Finished: 846 || Started: 17\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 37016 || New rows count: 36990 || Dropped rows based on   age_cat  : 26\n",
      "Original rows count: 36990 || New rows count: 36990 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2015/London2015_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_16}/{LDN}{YEAR_16}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_16}/{LDN}{YEAR_16}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_16}/{LDN}{YEAR_16}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_16}/{LDN}{YEAR_16}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 45202 || New rows count: 39217 || Dropped Rows: 5985\n",
      "** Dropping rows with splits that only contain time: Finished: 448 || Started: 9\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 38760 || New rows count: 38760 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 38760 || New rows count: 38760 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2016/London2016_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_17}/{LDN}{YEAR_17}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_17}/{LDN}{YEAR_17}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_17}/{LDN}{YEAR_17}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_17}/{LDN}{YEAR_17}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 45155 || New rows count: 39692 || Dropped Rows: 5463\n",
      "** Dropping rows with splits that only contain time: Finished: 379 || Started: 16\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 39297 || New rows count: 39296 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 39296 || New rows count: 39296 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2017/London2017_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_18}/{LDN}{YEAR_18}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_18}/{LDN}{YEAR_18}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_18}/{LDN}{YEAR_18}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_18}/{LDN}{YEAR_18}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 47667 || New rows count: 40773 || Dropped Rows: 6894\n",
      "** Dropping rows with splits that only contain time: Finished: 338 || Started: 7\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 40428 || New rows count: 40416 || Dropped rows based on   age_cat  : 12\n",
      "Original rows count: 40416 || New rows count: 40416 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2018/London2018_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_19}/{LDN}{YEAR_19}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_19}/{LDN}{YEAR_19}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_19}/{LDN}{YEAR_19}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_19}/{LDN}{YEAR_19}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 49318 || New rows count: 42737 || Dropped Rows: 6581\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 42737 || New rows count: 42737 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 42737 || New rows count: 42737 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2019/London2019_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([7276, 12700, 39577], dtype='int64')\n",
      "Invalid split time: k_10_time > k_15_time\n",
      "Index([12700], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([9363, 12546, 17925, 19882, 25407, 27703, 30180, 31301, 36861, 37235], dtype='int64')\n",
      "Invalid split time: k_15_time > k_20_time\n",
      "Index([19882], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([ 1112,  1121,  1380,  1403,  1431,  1920,  1991,  2173,  2289,  2342,\n",
      "       ...\n",
      "       40703, 40755, 40796, 40836, 40849, 40856, 41920, 42271, 42532, 42641],\n",
      "      dtype='int64', length=243)\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([1121, 32585, 37157], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([10199, 13179, 28912, 37298, 39577, 40935], dtype='int64')\n",
      "Invalid split time: k_half_time > k_25_time\n",
      "Index([28912, 40935], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([2575, 12700, 18525, 22476, 24082, 25407, 26714, 37235, 39981], dtype='int64')\n",
      "Invalid split time: k_30_time > k_35_time\n",
      "Index([2575], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([2287, 6714, 34598, 39458, 41072, 41213, 41526, 42712, 42729], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([6714, 41072, 41526, 42712], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([31437, 40036, 40799], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([40799], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 279 || Finished: 277 || Started: 2\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([12700], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([9363, 12546, 15272, 19882, 27703, 30180, 31301, 36861], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([   27,  1112,  1121,  1380,  1403,  1431,  1991,  2173,  2289,  2342,\n",
      "       ...\n",
      "       40275, 40703, 40755, 40836, 40849, 40856, 41920, 42271, 42532, 42641],\n",
      "      dtype='int64', length=251)\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([1121], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([10199, 13179, 34083, 37298, 39577, 40935], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([12700, 18525, 22476, 24082, 25407, 26714, 37235, 39981, 42426], dtype='int64')\n",
      "Invalid split time: k_30_time > k_35_time\n",
      "Index([22476], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([2287, 6714, 34598, 39458, 41072, 41213, 41526, 42712, 42729], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([6714, 41072, 41526, 42712, 42729], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([4804, 24084, 30311, 31437, 39577, 40036, 40059, 40799], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([4804, 40799], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 290 || Finished: 288 || Started: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_21}/{LDN}{YEAR_21}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_21}/{LDN}{YEAR_21}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_21}/{LDN}{YEAR_21}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_21}/{LDN}{YEAR_21}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 41594 || New rows count: 36129 || Dropped Rows: 5465\n",
      "** Dropping rows with splits that only contain time: Finished: 2 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 36127 || New rows count: 36124 || Dropped rows based on   age_cat  : 3\n",
      "Original rows count: 36124 || New rows count: 36124 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2021/London2021_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([  266,  1610,  1879,  3412,  4161,  7170,  7295,  8211,  8306,  9984,\n",
      "       11316, 12124, 12751, 13592, 17228, 19602, 20612, 21696, 24433, 25983,\n",
      "       26229, 28214, 31547, 32627, 33186, 33922, 35467],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([ 1685,  2330,  7168,  7973, 12727, 12982, 13390, 13490, 19459, 20583,\n",
      "       21620, 24170, 25217, 27209, 28261, 29418, 32724],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_15_time > k_20_time\n",
      "Index([27209], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([ 2410,  3496,  4840,  5248,  5528,  7284,  7464,  9295,  9657, 10303,\n",
      "       11848, 13589, 16194, 16364, 16865, 18219, 18720, 20164, 20192, 22020,\n",
      "       22598, 26342, 29537, 30371, 31483, 32411, 33247, 33902, 34773],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([18720], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([1020, 4590, 6160, 8515, 13564, 19835, 23994, 25934], dtype='int64')\n",
      "Invalid split time: k_half_time > k_25_time\n",
      "Index([23994], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([2330, 2958, 22096, 26609, 27228, 29455], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 6210,  8620, 10381, 11055, 11596, 13493, 16592, 20092, 21814, 22598,\n",
      "       23054, 23364, 24740, 25174, 30173, 32864, 33186, 34773],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1826,  1925,  2013,  2029,  2352,  4664,  4823,  5966,  6293,  8014,\n",
      "        9414, 10303, 10361, 10860, 11397, 11546, 11848, 15050, 15686, 16163,\n",
      "       16557, 18029, 18274, 18938, 19388, 19835, 19976, 20103, 20197, 20650,\n",
      "       21107, 21145, 21240, 22007, 22349, 22994, 23558, 24045, 24173, 24177,\n",
      "       24882, 26456, 26956, 27530, 29214, 29982, 30480, 30837, 31145, 32271,\n",
      "       33285, 34080, 34188, 34265, 34718, 34795, 35311, 35422, 35425, 35591],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([34188], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 1572,  2326,  5654, 10324, 15545, 19396, 21885, 22700, 26932, 27009,\n",
      "       29687, 30584, 33807],\n",
      "      dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 171 || Finished: 169 || Started: 2\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([  266,  1610,  1879,  3412,  4161,  7170,  7295,  8211,  9984, 13592,\n",
      "       17228, 18486, 19602, 20612, 21696, 22349, 24433, 24487, 26229, 28214,\n",
      "       28226, 31547, 32152, 35467],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([ 1685,  2330,  7168,  7973, 10371, 12982, 13390, 13490, 20583, 21620,\n",
      "       24170, 25217, 27209, 29418, 32724],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([ 2410,  5248,  5528,  7284,  7464,  7761,  9295,  9657, 10303, 11848,\n",
      "       13589, 16194, 16364, 16865, 18720, 20164, 22020, 22598, 24644, 25781,\n",
      "       26342, 26812, 28191, 29650, 30371, 31483, 32411, 33247, 33902, 34773],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([18720, 20164], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([1020, 4590, 6160, 19835, 25934], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([2330, 7862, 22096, 26609, 27228], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 1283,  6210,  6264,  6683,  7761,  8620, 10076, 10381, 11055, 11596,\n",
      "       12164, 13493, 16592, 20092, 21620, 21814, 22598, 23054, 23364, 24439,\n",
      "       24740, 25174, 30173, 32864, 33186, 34773],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1826,  1925,  1964,  2013,  2352,  3249,  3412,  4823,  5966,  6293,\n",
      "        6980,  8014,  9414,  9577, 10298, 10303, 10361, 10582, 10856, 10860,\n",
      "       10866, 11316, 11397, 11427, 11546, 11848, 11971, 15050, 15350, 15651,\n",
      "       15686, 16163, 16557, 18029, 18274, 18938, 19388, 19835, 19976, 20103,\n",
      "       20650, 21107, 21145, 21240, 22007, 22627, 22994, 23558, 24045, 24173,\n",
      "       24177, 24882, 25472, 26456, 26956, 27500, 27530, 27730, 28382, 29958,\n",
      "       29982, 30466, 30480, 30837, 31145, 32271, 33285, 33606, 33950, 34080,\n",
      "       34188, 34265, 34418, 34671, 34718, 34795, 35311, 35324, 35422, 35425,\n",
      "       35591],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([34188], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([1572, 2326, 10324, 12428, 15545, 21885, 22700, 24448, 26932, 27009,\n",
      "       30584],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([12428], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 188 || Finished: 185 || Started: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_22}/{LDN}{YEAR_22}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_22}/{LDN}{YEAR_22}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_22}/{LDN}{YEAR_22}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_22}/{LDN}{YEAR_22}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 46993 || New rows count: 40812 || Dropped Rows: 6181\n",
      "** Dropping rows with splits that only contain time: Finished: 1 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 40811 || New rows count: 40810 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 40810 || New rows count: 40810 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2022/London2022_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([1490, 5053, 20885, 23642], dtype='int64')\n",
      "Invalid split time: k_10_time > k_15_time\n",
      "Index([1490, 5053, 23642], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([ 5622,  5783, 12849, 13774, 19723, 22595, 22968, 28339, 28566, 28688,\n",
      "       30330, 31837, 34185, 37370],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_15_time > k_20_time\n",
      "Index([30330], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([ 3796,  6677,  6846,  7859,  8711,  9206, 10517, 10953, 11023, 12429,\n",
      "       13008, 14624, 16151, 16781, 17765, 21090, 22926, 23620, 25849, 28080,\n",
      "       28118, 28632, 29747, 29753, 32420, 32994, 38472, 38705],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([9206], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([1313, 6391, 27706, 30587, 31459], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([7566, 11327, 23092, 28339, 29498, 36251, 40510], dtype='int64')\n",
      "Invalid split time: k_25_time > k_30_time\n",
      "Index([36251], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 1175,  8916, 11561, 14759, 14861, 18892, 19810, 23150, 25301, 25501,\n",
      "       26073, 30330, 38025, 39625, 39842, 40201, 40288, 40462],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_30_time > k_35_time\n",
      "Index([40288], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1266,  1353,  1827,  3027,  5074,  6177,  7615,  9703, 10755, 11216,\n",
      "       11219, 11371, 11700, 13727, 14619, 15254, 16033, 16095, 18970, 19521,\n",
      "       19964, 21356, 22218, 22790, 23168, 23203, 23843, 28977, 28998, 29587,\n",
      "       29966, 30404, 30587, 33467, 33470, 33876, 33933, 34555, 36559, 37867,\n",
      "       37928, 38123, 38323, 39250, 39548, 39661, 40180, 40353],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([22790], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 3291,  4637,  5532,  7399, 11327, 11410, 17812, 18447, 18729, 21559,\n",
      "       24394, 25420, 26885, 27706, 27816, 31836, 33318, 36585, 40200],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([18729, 25420, 26885, 36585, 40200], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 138 || Finished: 138 || Started: 0\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([5053, 19207, 23642], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([ 5622,  5783, 12849, 13774, 19723, 22968, 28339, 28688, 30330, 31837,\n",
      "       34185, 37370],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([ 3796,  6677,  7859,  8711,  9482, 10517, 10953, 12123, 12429, 13008,\n",
      "       13846, 14211, 14624, 16754, 16781, 17765, 19397, 21090, 22469, 22926,\n",
      "       25440, 25849, 26665, 27904, 28080, 28632, 29753, 32420, 32994, 38305,\n",
      "       38705],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([1313, 6391, 16353, 22766, 27706, 31459], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([7566, 9006, 11327, 23092, 28339, 29498, 36251, 39386, 40510], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 8916, 11561, 14759, 17681, 18892, 19810, 23150, 25301, 25501, 26073,\n",
      "       27697, 30330, 38025, 39625, 39842, 40201, 40288, 40462],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1353,  1827,  3027,  6177,  6566,  7615,  7987,  9703, 10755, 11216,\n",
      "       11219, 11371, 11700, 12403, 16033, 16095, 18970, 19521, 19964, 21356,\n",
      "       22218, 22790, 23168, 23203, 23843, 25765, 28977, 28998, 30404, 30587,\n",
      "       33467, 33876, 33933, 34555, 37867, 37928, 38309, 38323, 39250, 39548,\n",
      "       39661, 40180, 40353],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([22790], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 3291,  4637,  5532,  7399,  9617, 11327, 17812, 18447, 18729, 21559,\n",
      "       24394, 25420, 26885, 27706, 27816, 31836, 33318, 36585, 40200],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([18729, 25420, 26885, 36585, 40200], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 137 || Finished: 137 || Started: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_file_raw_path = f\"{LDN_RAW_PATH}/{LDN}{YEAR_23}/{LDN}{YEAR_23}_full.csv\"\n",
    "ldn_file_cln_path = f\"{LDN_CLN_PATH}/{LDN}{YEAR_23}/{LDN}{YEAR_23}_clean.csv\"\n",
    "ldn_file_knn_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_23}/{LDN}{YEAR_23}_knn_impute.csv\"\n",
    "ldn_file_iter_imp_path = f\"{LDN_IMP_PATH}/{LDN}{YEAR_23}/{LDN}{YEAR_23}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 53077 || New rows count: 49083 || Dropped Rows: 3994\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 49083 || New rows count: 49083 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 49083 || New rows count: 49083 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80-84', '80+', '85+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/London/London2023/London2023_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_ldn = london_cleaner(df_ldn, SPLITS_KEYS, LDN_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ldn):\n",
    "    save_df(df_ldn, ldn_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ldn_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ldn = pd.read_csv(ldn_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ldn, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([ 2036,  3951,  4002,  5161,  5441,  5480,  5786,  6047,  6707,  8632,\n",
      "        8918,  9304,  9517,  9929, 10111, 10803, 11724, 11873, 13548, 14611,\n",
      "       15726, 15992, 16095, 16374, 16982, 20260, 21190, 24639, 24950, 25615,\n",
      "       27609, 29920, 30864, 34867, 34949, 35173, 35501, 44878, 45255, 45260,\n",
      "       46163, 48592],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_10_time > k_15_time\n",
      "Index([3951, 6047, 24950, 30864], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([  918,  1338,  1479,  1522,  1683,  1738,  2362,  2528,  3862,  4432,\n",
      "       ...\n",
      "       47299, 47479, 47868, 47908, 48080, 48083, 48498, 48743, 48876, 49032],\n",
      "      dtype='int64', length=160)\n",
      "Invalid split time: k_15_time > k_20_time\n",
      "Index([8828, 24406, 45505, 45506], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([  874,  1061,  2076,  2674,  2799,  2992,  3185,  3230,  3514,  3840,\n",
      "        4144,  4526,  4533,  4597,  4812,  5902,  6050,  6514,  6522,  6571,\n",
      "        6703,  6964,  9258, 10122, 10440, 10563, 11146, 12095, 12273, 12757,\n",
      "       13156, 13340, 14615, 14801, 15187, 17593, 18257, 18561, 18874, 19120,\n",
      "       19385, 19982, 21215, 23519, 24132, 24657, 25159, 25219, 25895, 26008,\n",
      "       26574, 28406, 28905, 30299, 31444, 32411, 32833, 33595, 33935, 34846,\n",
      "       35150, 35335, 37310, 38342, 38907, 39170, 39352, 39520, 40091, 40224,\n",
      "       41190, 42784, 42931, 43731, 44084, 44097, 46029, 46349, 46834, 46865,\n",
      "       47047, 47595, 47895, 48041, 48044, 48149, 48237],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([13156, 13340, 14615, 18257, 18874, 31444, 37310, 48044], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([2603, 7091, 16868, 25177, 36656], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([ 4611,  4857,  5056,  5150,  5520,  6269,  6431,  6513,  6628,  7920,\n",
      "       ...\n",
      "       46427, 46559, 47000, 47063, 47415, 47918, 47964, 48043, 48961, 49076],\n",
      "      dtype='int64', length=143)\n",
      "Invalid split time: k_25_time > k_30_time\n",
      "Index([4857], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 2447,  2967,  3170,  5027,  5432,  5782,  6522,  6756,  6845,  7136,\n",
      "       ...\n",
      "       44309, 44530, 44902, 45187, 45282, 46191, 47445, 47785, 48554, 49046],\n",
      "      dtype='int64', length=108)\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1165,  3971,  4144,  6703,  7016,  7912,  8782,  8874,  9240, 10827,\n",
      "       11045, 12535, 15642, 20946, 23010, 26254, 27609, 29453, 31222, 31477,\n",
      "       32833, 34924, 34947, 38209, 39557, 41541, 42433, 44457, 45736],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([38209], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 1647,  4812,  5490,  7091,  8109, 15807, 18096, 19197, 21599, 24305,\n",
      "       28175, 28323, 30726, 33305, 34311, 36807, 38348, 38907, 39200, 39374,\n",
      "       44740, 47586],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([15807, 19197, 24305, 30726, 38348], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 572 || Finished: 561 || Started: 11\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ldn, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([ 3951,  5441,  5786,  6707,  7926,  8233,  9304,  9517,  9929, 10803,\n",
      "       10857, 11724, 11873, 13548, 14611, 14895, 15726, 15992, 16095, 16982,\n",
      "       19892, 24639, 24950, 25615, 27609, 28083, 28756, 30864, 34949, 35173,\n",
      "       35501, 37497, 44878, 45974, 46163, 48592],\n",
      "      dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([  918,  1338,  1479,  1522,  1581,  1738,  2362,  2528,  4432,  4452,\n",
      "       ...\n",
      "       46924, 47242, 47299, 47445, 47908, 48083, 48498, 48743, 48839, 49032],\n",
      "      dtype='int64', length=152)\n",
      "Invalid split time: k_15_time > k_20_time\n",
      "Index([8828, 45505, 45506], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([  874,  1061,  1093,  2674,  2799,  2992,  3185,  3230,  3489,  3514,\n",
      "        4144,  4526,  4533,  4597,  4812,  5902,  6050,  6514,  6522,  6703,\n",
      "        9258,  9774,  9935, 10563, 11146, 12095, 12273, 12757, 13156, 14615,\n",
      "       14801, 15187, 17593, 18257, 18482, 18561, 19385, 19985, 21215, 21599,\n",
      "       22433, 22730, 23519, 24132, 24657, 25219, 25699, 25895, 26008, 26157,\n",
      "       26574, 28905, 30299, 30373, 31444, 32411, 32833, 33595, 33935, 34846,\n",
      "       34848, 35150, 35335, 35338, 37310, 38339, 38907, 39170, 39352, 39520,\n",
      "       40091, 40224, 41190, 41528, 42784, 42931, 43731, 43921, 44097, 44703,\n",
      "       44790, 46029, 46349, 46834, 46865, 47047, 47595, 47818, 48041, 48044,\n",
      "       48237, 48693],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_20_time > k_half_time\n",
      "Index([13156, 18257], dtype='int64')\n",
      "Invalid split time diff: k_25_time (non-cumulative) > (k_25_time - k_half_time + 5)\n",
      "Index([2603, 4141, 7091, 14916, 32301, 36656, 40078], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([ 2893,  4611,  4857,  5150,  6269,  6431,  6513,  7920,  8537,  8563,\n",
      "       ...\n",
      "       46442, 46809, 47000, 47063, 47415, 47897, 47918, 47964, 48043, 48961],\n",
      "      dtype='int64', length=155)\n",
      "Invalid split time: k_25_time > k_30_time\n",
      "Index([2893, 4857], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([ 3170,  4988,  5027,  5432,  5782,  6522,  6756,  6845,  7136,  7848,\n",
      "       ...\n",
      "       46191, 46262, 46588, 47351, 47445, 47475, 47785, 47819, 48554, 49046],\n",
      "      dtype='int64', length=143)\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([ 1165,  3971,  4144,  6703,  7016,  8782,  9240, 10827, 10958, 11045,\n",
      "       12535, 14259, 15641, 15642, 17675, 20946, 22537, 23010, 28307, 29453,\n",
      "       31222, 32833, 34924, 34947, 38209, 40633, 41541, 41708, 42433, 44457,\n",
      "       45736, 45933, 48114],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([38209], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 1647,  4812,  5490,  7091,  8109, 11118, 12429, 15807, 18096, 19197,\n",
      "       21599, 24305, 25652, 28175, 30726, 33305, 34311, 36807, 38348, 38907,\n",
      "       39200, 39374, 44740, 47446, 47586],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([15807, 19197, 24305, 30726, 33305], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 615 || Finished: 601 || Started: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ldn, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ldn_file_knn_imp_path)\n",
    "save_df(df_iter, ldn_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ldn_file_raw_path, ldn_file_cln_path, ldn_file_knn_imp_path, ldn_file_iter_imp_path, df_ldn, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_COLS_TO_DROP = [\"idp\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw file path.\n",
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_13}/{HAM}{YEAR_13}_full.csv\"\n",
    "# Clean file path.\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_13}/{HAM}{YEAR_13}_clean.csv\"\n",
    "# Imputed file path.\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_13}/{HAM}{YEAR_13}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_13}/{HAM}{YEAR_13}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 15135 || New rows count: 11872 || Dropped Rows: 3263\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 11872 || New rows count: 11872 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 11872 || New rows count: 11872 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 29 || Started: 1\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2013/Hamburg2013_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([11212], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([880, 2073, 4865], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([9117], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([1071, 2073, 6729], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([145, 187, 628, 2430, 2979, 5505, 6239, 7642, 8525, 11212, 11216], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([145, 187, 11212], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([  246,   644,  1454,  2515,  6805,  7170,  8020,  8668,  9895, 10138,\n",
      "       10215, 10298, 11121, 11720],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([246, 644, 1454, 2515, 7170, 8020, 8668, 9895, 10138, 10215, 11720], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 31 || Finished: 30 || Started: 1\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([11212], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([36, 880, 1616, 4865], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([8139], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([2628], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([145, 187, 628, 2430, 2979, 5505, 6239, 7134, 7642, 8525, 11212, 11216], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([145, 187, 11212], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([  246,   644,  1454,  2515,  6805,  7170,  8020,  8668,  9895, 10138,\n",
      "       10215, 10296, 10298, 11121, 11720],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([246, 644, 1454, 7170, 8020, 8668, 9895, 10138, 10215], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 33 || Finished: 32 || Started: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_14}/{HAM}{YEAR_14}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_14}/{HAM}{YEAR_14}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_14}/{HAM}{YEAR_14}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_14}/{HAM}{YEAR_14}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 16695 || New rows count: 13296 || Dropped Rows: 3399\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 13296 || New rows count: 13295 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 13295 || New rows count: 13295 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 13 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2014/Hamburg2014_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([3212], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([1022], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([6173], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([1676, 3457, 3460], dtype='int64')\n",
      "Invalid split time: k_30_time > k_35_time\n",
      "Index([3457], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1082, 2225, 3057, 5774, 7397, 11717, 13174], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([1364, 2046, 2274, 2994, 6173, 7970, 8358, 8821, 9051], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([1364, 2274, 2994, 6173, 7970, 8358, 9051], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 21 || Finished: 20 || Started: 1\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([6173], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([3457], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1082, 2225, 3057, 5774, 7397, 9391, 9795, 11717, 12322], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([1091, 1364, 2046, 2274, 2994, 6173, 7970, 8358, 8821, 9051], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([1364, 2274, 2994, 6173, 7970, 8358], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 20 || Finished: 20 || Started: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_15}/{HAM}{YEAR_15}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_15}/{HAM}{YEAR_15}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_15}/{HAM}{YEAR_15}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_15}/{HAM}{YEAR_15}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 19205 || New rows count: 15259 || Dropped Rows: 3946\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 15259 || New rows count: 15257 || Dropped rows based on   age_cat  : 2\n",
      "Original rows count: 15257 || New rows count: 15257 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 17 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2015/Hamburg2015_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([3836], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([10785, 11191], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([2265], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([8072], dtype='int64')\n",
      "Invalid split time: k_25_time > k_30_time\n",
      "Index([8072], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([1427, 9527], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([  351,  2834,  3502,  3761,  5007,  5171,  5510,  5538,  5649,  7682,\n",
      "        8711,  8721, 10096, 12716, 15061],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([2834, 3502, 3761, 5007, 5538, 7682, 10096, 15061], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 1050,  1250,  1280,  2421,  3017,  4332,  4561,  4620,  5622,  7265,\n",
      "        9041, 10106, 10590, 11626, 11742, 12651],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([1050, 1250, 1280, 2421, 4332, 4561, 7265, 9041, 10106, 11626, 11742,\n",
      "       12651],\n",
      "      dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 38 || Finished: 36 || Started: 2\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([3420, 10785, 11191], dtype='int64')\n",
      "Invalid split time diff: k_half_time (non-cumulative) > (k_half_time - k_20_time + 5)\n",
      "Index([2265], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([1728, 8072], dtype='int64')\n",
      "Invalid split time: k_25_time > k_30_time\n",
      "Index([8072], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([1427, 9527], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([  351,  2834,  3502,  3761,  5007,  5171,  5510,  5538,  5649,  7682,\n",
      "        8711,  8721, 10096, 12716, 15061],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([2834, 3502, 3761, 5007, 5538, 7682, 10096], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([ 1050,  1250,  1280,  2421,  3017,  4332,  4561,  4620,  5622,  7265,\n",
      "        9041, 10106, 10590, 11626, 11742, 12651],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([1050, 1250, 1280, 2421, 4561, 7265, 9041, 10106, 11742, 12651], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 39 || Finished: 37 || Started: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_16}/{HAM}{YEAR_16}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_16}/{HAM}{YEAR_16}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_16}/{HAM}{YEAR_16}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_16}/{HAM}{YEAR_16}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 16011 || New rows count: 12540 || Dropped Rows: 3471\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 12540 || New rows count: 12537 || Dropped rows based on   age_cat  : 3\n",
      "Original rows count: 12537 || New rows count: 12537 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 5 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2016/Hamburg2016_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([99, 2354, 2356, 2586, 3702, 8749, 9085], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([2992], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([4314, 12113], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([570, 676, 2992, 3319, 3703, 3779, 3921, 9320, 10034], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([570, 676, 3921], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([2599, 2616, 4609, 5804, 5885, 6088, 6908, 8171, 8578, 8824, 10021,\n",
      "       12484],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([5804, 6908, 8171], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 30 || Finished: 26 || Started: 4\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([99, 2354, 2356, 2586, 3702, 8749, 9085], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([4250], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([570, 676, 2992, 3319, 3779, 3921, 9320, 10034], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([570, 3921], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([2599, 2616, 5804, 5885, 6088, 6908, 7519, 8171, 8578, 8824, 10021,\n",
      "       12484],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([5804, 6908, 8171], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 28 || Finished: 25 || Started: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_17}/{HAM}{YEAR_17}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_17}/{HAM}{YEAR_17}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_17}/{HAM}{YEAR_17}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_17}/{HAM}{YEAR_17}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 15638 || New rows count: 12396 || Dropped Rows: 3242\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 12396 || New rows count: 12391 || Dropped rows based on   age_cat  : 5\n",
      "Original rows count: 12391 || New rows count: 12391 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 15 || Started: 3\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2017/Hamburg2017_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([3245], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([2131], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([5810], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1654, 3812, 9083], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([764, 2231, 2313, 4153, 5395, 8535, 10357, 10809, 11148, 12246], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([764, 4153, 5395, 10809, 11148, 12246], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 16 || Finished: 16 || Started: 0\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([5810, 6505], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1654, 3812, 9083], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([764, 2231, 2313, 4153, 5395, 7899, 8535, 10357, 10809, 11148, 12246], dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([764, 2231, 4153, 5395, 10809, 11148, 12246], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 16 || Finished: 16 || Started: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_18}/{HAM}{YEAR_18}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_18}/{HAM}{YEAR_18}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_18}/{HAM}{YEAR_18}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_18}/{HAM}{YEAR_18}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 14010 || New rows count: 10670 || Dropped Rows: 3340\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 10670 || New rows count: 10668 || Dropped rows based on   age_cat  : 2\n",
      "Original rows count: 10668 || New rows count: 10668 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2018/Hamburg2018_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([547, 874, 5417, 9682], dtype='int64')\n",
      "Invalid split time diff: k_30_time (non-cumulative) > (k_30_time - k_25_time + 5)\n",
      "Index([2046, 4028], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([7484, 8495, 9636], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1432, 2927, 3167, 3672, 3890, 5084, 6116, 9267], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([2927, 3167, 5084], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([  706,   997,  1717,  2711,  3471,  3515,  3534,  4261,  6678,  6928,\n",
      "        7925,  8028,  9017, 10365, 10502],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([706, 997, 1717, 2711, 3471, 3534, 4261, 6678, 6928, 7925, 8028, 9017,\n",
      "       10502],\n",
      "      dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 32 || Finished: 31 || Started: 1\n"
     ]
    }
   ],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid split time diff: k_15_time (non-cumulative) > (k_15_time - k_10_time + 5)\n",
      "Index([547, 874, 5417], dtype='int64')\n",
      "Invalid split time diff: k_20_time (non-cumulative) > (k_20_time - k_15_time + 5)\n",
      "Index([6901], dtype='int64')\n",
      "Invalid split time diff: k_35_time (non-cumulative) > (k_35_time - k_30_time + 5)\n",
      "Index([7484, 8495, 9636], dtype='int64')\n",
      "Invalid split time diff: k_40_time (non-cumulative) > (k_40_time - k_35_time + 5)\n",
      "Index([1432, 2927, 3167, 5084, 6116], dtype='int64')\n",
      "Invalid split time: k_35_time > k_40_time\n",
      "Index([2927, 3167, 5084], dtype='int64')\n",
      "Invalid split time diff: k_finish_time (non-cumulative) > (k_finish_time - k_40_time + 5)\n",
      "Index([  706,   997,  1717,  2711,  3471,  3515,  3534,  4261,  5803,  6678,\n",
      "        6928,  7925,  8028,  8444,  9017, 10365, 10502],\n",
      "      dtype='int64')\n",
      "Invalid split time: k_40_time > k_finish_time\n",
      "Index([706, 997, 1717, 2711, 3471, 3534, 4261, 6678, 7925, 8028, 9017, 10502], dtype='int64')\n",
      "\n",
      "** Dropping invalid splits, Total Count: 29 || Finished: 28 || Started: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sika/miniforge3/envs/ML_mac_23/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_19}/{HAM}{YEAR_19}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_19}/{HAM}{YEAR_19}_clean.csv\"\n",
    "ham_file_knn_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_19}/{HAM}{YEAR_19}_knn_impute.csv\"\n",
    "ham_file_iter_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_19}/{HAM}{YEAR_19}_iter_impute.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 13498 || New rows count: 10468 || Dropped Rows: 3030\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 10468 || New rows count: 10453 || Dropped rows based on   age_cat  : 15\n",
      "Original rows count: 10453 || New rows count: 10453 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2019/Hamburg2019_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_22}/{HAM}{YEAR_22}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_22}/{HAM}{YEAR_22}_clean.csv\"\n",
    "ham_file_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_22}/{HAM}{YEAR_22}_imputed.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 10416 || New rows count: 6888 || Dropped Rows: 3528\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 6888 || New rows count: 6840 || Dropped rows based on   age_cat  : 48\n",
      "Original rows count: 6840 || New rows count: 6840 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2022/Hamburg2022_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_file_raw_path = f\"{HAM_RAW_PATH}/{HAM}{YEAR_23}/{HAM}{YEAR_23}_full.csv\"\n",
    "ham_file_cln_path = f\"{HAM_CLN_PATH}/{HAM}{YEAR_23}/{HAM}{YEAR_23}_clean.csv\"\n",
    "ham_file_imp_path = f\"{HAM_IMP_PATH}/{HAM}{YEAR_23}/{HAM}{YEAR_23}_imputed.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 11757 || New rows count: 9002 || Dropped Rows: 2755\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 9002 || New rows count: 8998 || Dropped rows based on   age_cat  : 4\n",
      "Original rows count: 8998 || New rows count: 8998 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** File has been saved in: `Marathons_Data/Clean/Hamburg/Hamburg2023/Hamburg2023_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_ham = pd.read_csv(ham_file_raw_path)\n",
    "# Cleaning The DataFrame\n",
    "df_ham = hamburg_cleaner(df_ham, SPLITS_KEYS, HAM_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_ham):\n",
    "    save_df(df_ham, ham_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{ham_file_cln_path}`\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.read_csv(ham_file_cln_path, dtype=DTYPE_DICT)\n",
    "missing_indices = get_indices_of_rows_missing_data(df_ham, SPLITS_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = preprocess_impute_fill(df_ham, missing_indices, knn_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = preprocess_impute_fill(df_ham, missing_indices, iter_imputer, mms, SPLITS_KEYS, drop_invalid_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_knn, ham_file_knn_imp_path)\n",
    "save_df(df_iter, ham_file_iter_imp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ham_file_raw_path, ham_file_cln_path, ham_file_knn_imp_path, ham_file_iter_imp_path, df_ham, df_knn, df_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Houston\n",
    "##### Pace and speed have been converted from min/mile and miles/h to sec/km and km/h respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOU_COLS_TO_DROP = [\"idp\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hou_file_raw_path = f\"{HOU_RAW_PATH}/{HOU}{YEAR_18}/{HOU}{YEAR_18}_full.csv\"\n",
    "hou_file_cln_path = f\"{HOU_CLN_PATH}/{HOU}{YEAR_18}/{HOU}{YEAR_18}_clean.csv\"\n",
    "hou_file_imp_path = f\"{HOU_IMP_PATH}/{HOU}{YEAR_18}/{HOU}{YEAR_18}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 7547 || New rows count: 7526 || Dropped Rows: 21\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 7526 || New rows count: 7526 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 7526 || New rows count: 7526 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with invalid age categories [12-15, 16-19, Elites]:\n",
      "Original rows count: 7526 || New rows count: 7388 || Dropped rows: 138\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** Dropping rows with invalid race state ['Other', 'DQ - No Reason Was Given', 'DQ - SWITCH from HALF to MARA']:\n",
      "Original rows count: 7388 || New rows count: 7374 || Dropped rows: 14\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 4\n",
      "** File has been saved in: `Marathons_Data/Clean/Houston/Houston2018/Houston2018_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_hou = pd.read_csv(hou_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_hou = houston_cleaner(df_hou, SPLITS_KEYS, HOU_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_hou):\n",
    "    save_df(df_hou, hou_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{hou_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hou_file_raw_path, hou_file_cln_path, hou_file_imp_path, df_hou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hou_file_raw_path = f\"{HOU_RAW_PATH}/{HOU}{YEAR_19}/{HOU}{YEAR_19}_full.csv\"\n",
    "hou_file_cln_path = f\"{HOU_CLN_PATH}/{HOU}{YEAR_19}/{HOU}{YEAR_19}_clean.csv\"\n",
    "hou_file_imp_path = f\"{HOU_IMP_PATH}/{HOU}{YEAR_19}/{HOU}{YEAR_19}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 7159 || New rows count: 7145 || Dropped Rows: 14\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 7145 || New rows count: 7145 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 7145 || New rows count: 7145 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with invalid age categories [12-15, 16-19, Elites]:\n",
      "Original rows count: 7145 || New rows count: 7015 || Dropped rows: 130\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** Dropping rows with invalid race state ['Other', 'DQ - No Reason Was Given', 'DQ - SWITCH from HALF to MARA']:\n",
      "Original rows count: 7015 || New rows count: 7003 || Dropped rows: 12\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 4\n",
      "** File has been saved in: `Marathons_Data/Clean/Houston/Houston2019/Houston2019_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_hou = pd.read_csv(hou_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_hou = houston_cleaner(df_hou, SPLITS_KEYS, HOU_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_hou):\n",
    "    save_df(df_hou, hou_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{hou_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hou_file_raw_path, hou_file_cln_path, hou_file_imp_path, df_hou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STO_COLS_TO_DROP = [\"idp\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_file_raw_path = f\"{STO_RAW_PATH}/{STO}{YEAR_21}/{STO}{YEAR_21}_full.csv\"\n",
    "sto_file_cln_path = f\"{STO_CLN_PATH}/{STO}{YEAR_21}/{STO}{YEAR_21}_clean.csv\"\n",
    "sto_file_imp_path = f\"{STO_IMP_PATH}/{STO}{YEAR_21}/{STO}{YEAR_21}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 12179 || New rows count: 7177 || Dropped Rows: 5002\n",
      "** Dropping rows with null values in `yob` and `gender` columns:\n",
      "Original rows count: 7177 || New rows count: 7126 || Dropped rows based on     yob    : 51\n",
      "Original rows count: 7126 || New rows count: 7126 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping non-adult runners (age < 18):\n",
      "Original rows count: 7126 || New rows count: 7125 || Dropped rows: 1\n",
      "** column name `yob` changed to `age_cat`.\n",
      "** File has been saved in: `Marathons_Data/Clean/Stockholm/Stockholm2021/Stockholm2021_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_sto = pd.read_csv(sto_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_sto = stockholm_cleaner(df_sto, SPLITS_KEYS, STO_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER, year=2021)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_sto):\n",
    "    save_df(df_sto, sto_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{sto_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sto_file_raw_path, sto_file_cln_path, sto_file_imp_path, df_sto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_file_raw_path = f\"{STO_RAW_PATH}/{STO}{YEAR_22}/{STO}{YEAR_22}_full.csv\"\n",
    "sto_file_cln_path = f\"{STO_CLN_PATH}/{STO}{YEAR_22}/{STO}{YEAR_22}_clean.csv\"\n",
    "sto_file_imp_path = f\"{STO_IMP_PATH}/{STO}{YEAR_22}/{STO}{YEAR_22}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 13593 || New rows count: 10161 || Dropped Rows: 3432\n",
      "** Dropping rows with null values in `yob` and `gender` columns:\n",
      "Original rows count: 10161 || New rows count: 10057 || Dropped rows based on     yob    : 104\n",
      "Original rows count: 10057 || New rows count: 10057 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping non-adult runners (age < 18):\n",
      "Original rows count: 10057 || New rows count: 10057 || Dropped rows: 0\n",
      "** column name `yob` changed to `age_cat`.\n",
      "** File has been saved in: `Marathons_Data/Clean/Stockholm/Stockholm2022/Stockholm2022_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_sto = pd.read_csv(sto_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_sto = stockholm_cleaner(df_sto, SPLITS_KEYS, STO_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER, year=2022)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_sto):\n",
    "    save_df(df_sto, sto_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{sto_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sto_file_raw_path, sto_file_cln_path, sto_file_imp_path, df_sto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston\n",
    "##### Pace and speed have been converted from min/mile and miles/h to sec/km and km/h respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_COLS_TO_DROP = [\"idp\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_14}/{BOS}{YEAR_14}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_14}/{BOS}{YEAR_14}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_14}/{BOS}{YEAR_14}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 35671 || New rows count: 32447 || Dropped Rows: 3224\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 32123 || New rows count: 32123 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 32123 || New rows count: 32123 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2014/Boston2014_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_15}/{BOS}{YEAR_15}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_15}/{BOS}{YEAR_15}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_15}/{BOS}{YEAR_15}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 30252 || New rows count: 27159 || Dropped Rows: 3093\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 26986 || New rows count: 26986 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 26986 || New rows count: 26986 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2015/Boston2015_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_16}/{BOS}{YEAR_16}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_16}/{BOS}{YEAR_16}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_16}/{BOS}{YEAR_16}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 30743 || New rows count: 27487 || Dropped Rows: 3256\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 27421 || New rows count: 27421 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 27421 || New rows count: 27421 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2016/Boston2016_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_17}/{BOS}{YEAR_17}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_17}/{BOS}{YEAR_17}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_17}/{BOS}{YEAR_17}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 30074 || New rows count: 27220 || Dropped Rows: 2854\n",
      "** Dropping rows with splits that only contain time: Finished: 0 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 27189 || New rows count: 27189 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 27189 || New rows count: 27189 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2017/Boston2017_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_18}/{BOS}{YEAR_18}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_18}/{BOS}{YEAR_18}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_18}/{BOS}{YEAR_18}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 29978 || New rows count: 26919 || Dropped Rows: 3059\n",
      "** Dropping rows with splits that only contain time: Finished: 9 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 26910 || New rows count: 26910 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 26910 || New rows count: 26910 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2018/Boston2018_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_19}/{BOS}{YEAR_19}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_19}/{BOS}{YEAR_19}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_19}/{BOS}{YEAR_19}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 30234 || New rows count: 27337 || Dropped Rows: 2897\n",
      "** Dropping rows with splits that only contain time: Finished: 37 || Started: 1\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 27299 || New rows count: 27299 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 27299 || New rows count: 27299 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2019/Boston2019_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_21}/{BOS}{YEAR_21}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_21}/{BOS}{YEAR_21}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_21}/{BOS}{YEAR_21}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 18074 || New rows count: 15645 || Dropped Rows: 2429\n",
      "** Dropping rows with splits that only contain time: Finished: 1 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 15644 || New rows count: 15644 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 15644 || New rows count: 15644 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2021/Boston2021_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_22}/{BOS}{YEAR_22}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_22}/{BOS}{YEAR_22}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_22}/{BOS}{YEAR_22}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 28500 || New rows count: 25217 || Dropped Rows: 3283\n",
      "** Dropping rows with splits that only contain time: Finished: 4 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 25213 || New rows count: 25213 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 25213 || New rows count: 25213 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2022/Boston2022_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_file_raw_path = f\"{BOS_RAW_PATH}/{BOS}{YEAR_23}/{BOS}{YEAR_23}_full.csv\"\n",
    "bos_file_cln_path = f\"{BOS_CLN_PATH}/{BOS}{YEAR_23}/{BOS}{YEAR_23}_clean.csv\"\n",
    "bos_file_imp_path = f\"{BOS_IMP_PATH}/{BOS}{YEAR_23}/{BOS}{YEAR_23}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 30105 || New rows count: 27058 || Dropped Rows: 3047\n",
      "** Dropping rows with splits that only contain time: Finished: 3 || Started: 0\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 27055 || New rows count: 27055 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 27055 || New rows count: 27055 || Dropped rows based on    gender  : 0\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Boston/Boston2023/Boston2023_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_bos = pd.read_csv(bos_file_raw_path, low_memory=False)\n",
    "# # Cleaning the DataFrame.\n",
    "df_bos = boston_cleaner(df_bos, SPLITS_KEYS, BOS_COLS_TO_DROP, COLS_ORDER)\n",
    "# # Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_bos):\n",
    "    save_df(df_bos, bos_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{bos_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bos_file_raw_path, bos_file_cln_path, bos_file_imp_path, df_bos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHI_COLS_TO_DROP = [\"idp\", \"finish\", \"run_no\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_14}/{CHI}{YEAR_14}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_14}/{CHI}{YEAR_14}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_14}/{CHI}{YEAR_14}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 50216 || New rows count: 41715 || Dropped Rows: 8501\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 41715 || New rows count: 41715 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 41715 || New rows count: 41715 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 27 || Started: 0\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 41688 || New rows count: 41323 || Dropped rows: 365\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2014/Chicago2014_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_15}/{CHI}{YEAR_15}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_15}/{CHI}{YEAR_15}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_15}/{CHI}{YEAR_15}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 46032 || New rows count: 39219 || Dropped Rows: 6813\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 39219 || New rows count: 39219 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 39219 || New rows count: 39219 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 18 || Started: 1\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 39200 || New rows count: 38868 || Dropped rows: 332\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2015/Chicago2015_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_16}/{CHI}{YEAR_16}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_16}/{CHI}{YEAR_16}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_16}/{CHI}{YEAR_16}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 49067 || New rows count: 41469 || Dropped Rows: 7598\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 41469 || New rows count: 41468 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 41468 || New rows count: 41468 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 22 || Started: 0\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 41446 || New rows count: 41141 || Dropped rows: 305\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2016/Chicago2016_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_17}/{CHI}{YEAR_17}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_17}/{CHI}{YEAR_17}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_17}/{CHI}{YEAR_17}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 54326 || New rows count: 45565 || Dropped Rows: 8761\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 45565 || New rows count: 45565 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 45565 || New rows count: 45565 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 34 || Started: 3\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 45528 || New rows count: 45289 || Dropped rows: 239\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2017/Chicago2017_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_18}/{CHI}{YEAR_18}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_18}/{CHI}{YEAR_18}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_18}/{CHI}{YEAR_18}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 55621 || New rows count: 45380 || Dropped Rows: 10241\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 45380 || New rows count: 45380 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 45380 || New rows count: 45380 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 25 || Started: 1\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 45354 || New rows count: 45119 || Dropped rows: 235\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2018/Chicago2018_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_19}/{CHI}{YEAR_19}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_19}/{CHI}{YEAR_19}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_19}/{CHI}{YEAR_19}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 55395 || New rows count: 46513 || Dropped Rows: 8882\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 46513 || New rows count: 46512 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 46512 || New rows count: 46512 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 4 || Started: 0\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 46508 || New rows count: 46265 || Dropped rows: 243\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2019/Chicago2019_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_21}/{CHI}{YEAR_21}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_21}/{CHI}{YEAR_21}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_21}/{CHI}{YEAR_21}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 33502 || New rows count: 26864 || Dropped Rows: 6638\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 26864 || New rows count: 26864 || Dropped rows based on   age_cat  : 0\n",
      "Original rows count: 26864 || New rows count: 26864 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 19 || Started: 0\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 26845 || New rows count: 26730 || Dropped rows: 115\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2021/Chicago2021_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_file_raw_path = f\"{CHI_RAW_PATH}/{CHI}{YEAR_22}/{CHI}{YEAR_22}_full.csv\"\n",
    "chi_file_cln_path = f\"{CHI_CLN_PATH}/{CHI}{YEAR_22}/{CHI}{YEAR_22}_clean.csv\"\n",
    "chi_file_imp_path = f\"{CHI_IMP_PATH}/{CHI}{YEAR_22}/{CHI}{YEAR_22}_imputed.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing Runners That did not start:\n",
      "Original rows count: 51087 || New rows count: 39939 || Dropped Rows: 11148\n",
      "** Dropping rows with null values in `age_cat` and `gender` columns:\n",
      "Original rows count: 39939 || New rows count: 39938 || Dropped rows based on   age_cat  : 1\n",
      "Original rows count: 39938 || New rows count: 39938 || Dropped rows based on    gender  : 0\n",
      "** Dropping rows with splits that only contain time: Finished: 7 || Started: 0\n",
      "** Dropping rows with invalid age categories [W-15, M-15, 19 and under]:\n",
      "Original rows count: 39931 || New rows count: 39790 || Dropped rows: 141\n",
      "** Replacing these age categories '20-24', '25-29', '30-34', and '35-39' by '18-39'\n",
      "** Replacing these age categories '70-74', '75-79', '80+' by '70+'\n",
      "** File has been saved in: `Marathons_Data/Clean/Chicago/Chicago2022/Chicago2022_clean.csv`\n"
     ]
    }
   ],
   "source": [
    "df_chi = pd.read_csv(chi_file_raw_path)\n",
    "# Cleaning the DataFrame.\n",
    "df_chi = chicago_cleaner(df_chi, SPLITS_KEYS, CHI_COLS_TO_DROP, SPLIT_NAME_DICT, COLS_ORDER)\n",
    "# Check if the DataFrame is valid before saving it.\n",
    "if valid_df(df_chi):\n",
    "    save_df(df_chi, chi_file_cln_path)\n",
    "    print(f\"** File has been saved in: `{chi_file_cln_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chi_file_raw_path, chi_file_cln_path, chi_file_imp_path, df_chi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_mac_23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
